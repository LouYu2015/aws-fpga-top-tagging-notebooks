{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import tables\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for models\n",
    "custom_weights_dir_q = os.path.expanduser(\"weights-quantized-224x224-fixval-best-final/\")\n",
    "custom_weights_dir = os.path.expanduser(\"weights-floatingpoint-224x224-fixval-best/\")\n",
    "saved_model_dir = os.path.expanduser(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported from utils \n",
    "# utils.py: https://github.com/nhanvtran/MachineLearningNotebooks/blob/nvt/bwcustomweights-validate/project-brainwave/utils.py\n",
    "def count_events(train_files):\n",
    "    import tables\n",
    "    n_events = 0\n",
    "    for train_file in train_files:\n",
    "        f = tables.open_file(train_file, 'r')\n",
    "        n_events += f.root.label.shape[0]\n",
    "        f.close()\n",
    "    return n_events\n",
    "\n",
    "def preprocess_images(size=64):\n",
    "    import tensorflow as tf\n",
    "    # Create a placeholder for our incoming images\n",
    "    in_height = size\n",
    "    in_width = size\n",
    "    in_images = tf.placeholder(tf.float32)\n",
    "    in_images.set_shape([None, in_height, in_width, 3])\n",
    "    \n",
    "    # Resize those images to fit our featurizer\n",
    "    if size==64:\n",
    "        out_width = 224\n",
    "        out_height = 224\n",
    "        image_tensors = tf.image.resize_images(in_images, [out_height,out_width])\n",
    "        image_tensors = tf.to_float(image_tensors)\n",
    "    elif size==224:\n",
    "        image_tensors = in_images\n",
    "        \n",
    "    return in_images, image_tensors\n",
    "\n",
    "def construct_classifier():\n",
    "    from keras.layers import Dropout, Dense, Flatten, Input\n",
    "    from keras.models import Model\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    K.set_session(tf.get_default_session())\n",
    "    \n",
    "    FC_SIZE = 1024\n",
    "    NUM_CLASSES = 2\n",
    "\n",
    "    in_layer = Input(shape=(1, 1, 2048,),name='input_1')\n",
    "    x = Dense(FC_SIZE, activation='relu', input_dim=(1, 1, 2048,),name='dense_1')(in_layer)\n",
    "    x = Flatten(name='flatten_1')(x)\n",
    "    preds = Dense(NUM_CLASSES, activation='softmax', input_dim=FC_SIZE, name='classifier_output')(x)\n",
    "    \n",
    "    model = Model(inputs = in_layer, outputs = preds)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def construct_model(quantized, saved_model_dir=None, starting_weights_directory=None, is_frozen=False, is_training=True, size=64):\n",
    "    from azureml.contrib.brainwave.models import Resnet50, QuantizedResnet50\n",
    "    import tensorflow as tf\n",
    "    from keras import backend as K\n",
    "    \n",
    "    # Convert images to 3D tensors [width,height,channel]\n",
    "    in_images, image_tensors = preprocess_images(size=size)\n",
    "\n",
    "    # Construct featurizer using quantized or unquantized ResNet50 model\n",
    "    \n",
    "    if not quantized:\n",
    "        featurizer = Resnet50(saved_model_dir, is_frozen=is_frozen, custom_weights_directory = starting_weights_directory)\n",
    "    else:\n",
    "        featurizer = QuantizedResnet50(saved_model_dir, is_frozen=is_frozen, custom_weights_directory = starting_weights_directory)\n",
    "    \n",
    "    features = featurizer.import_graph_def(input_tensor=image_tensors, is_training=is_training)\n",
    "    \n",
    "    # Construct classifier\n",
    "    with tf.name_scope('classifier'):\n",
    "        classifier = construct_classifier()\n",
    "        preds = classifier(features)\n",
    "    \n",
    "    # Initialize weights\n",
    "    sess = tf.get_default_session()\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    if not is_frozen:\n",
    "        featurizer.restore_weights(sess)\n",
    "    \n",
    "    if starting_weights_directory is not None:\n",
    "        print(\"loading classifier weights from\", starting_weights_directory+'/class_weights_best.h5')\n",
    "        classifier.load_weights(starting_weights_directory+'/class_weights_best.h5')\n",
    "        \n",
    "    return in_images, image_tensors, features, preds, featurizer, classifier \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# for 224x224:\n",
    "datadir = \"./\"\n",
    "data_size = 224 #image width/height\n",
    "n_test_file = 1\n",
    "test_files = glob.glob(os.path.join(datadir, 'test_file_*'))\n",
    "n_test_events = count_events(test_files)\n",
    "print(\"n_test_events =\", n_test_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "with sess.as_default():\n",
    "    print(\"Loading quantized model\")\n",
    "    in_images, image_tensors, features, preds, quantized_featurizer, classifier = construct_model(quantized=True, \n",
    "                                                                                                  saved_model_dir=saved_model_dir, \n",
    "                                                                                                  starting_weights_directory=custom_weights_dir_q, \n",
    "                                                                                                  is_training=False, \n",
    "                                                                                                  size=data_size)\n",
    "    print(preds.name)\n",
    "    pred_node_names = [preds.name[:-2]]\n",
    "\n",
    "    K.set_learning_phase(0)\n",
    "    saver = tf.train.Saver()\n",
    "    tfoutpath=custom_weights_dir_q+'/tf.checkpoint'\n",
    "\n",
    "    from tensorflow.python.framework import graph_util\n",
    "    from tensorflow.python.framework import graph_io\n",
    "    \n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "\n",
    "    f = 'constantgraph.pb.ascii'\n",
    "    tf.train.write_graph(constant_graph, custom_weights_dir_q, f, as_text=True)\n",
    "    print('saved the graph definition in ascii format at: ', os.path.join(custom_weights_dir_q, f))\n",
    "\n",
    "    f = 'constantgraph.pb'\n",
    "    tf.train.write_graph(constant_graph, custom_weights_dir_q, f, as_text=False)\n",
    "    print('saved the graph definition in pb format at: ', os.path.join(custom_weights_dir_q, f))\n",
    "\n",
    "    saver.save(sess, tfoutpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
