{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from .pb file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will load and return the graph.\n",
    "\n",
    "* `model_file_name`: path to a `.pb` file.\n",
    "* `node_mapping`: mapping from the name of node in the graph to a Tensorflow node in current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "def load_graph(sess, model_file_name, node_mapping={}):\n",
    "    with gfile.GFile(model_file_name, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, node_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will load the top-tagging model weights.\n",
    "\n",
    "Please change the `model_file_name` to the file name of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Create a placeholder for the input\n",
    "    input_node = tf.placeholder(tf.float32, shape = [None, 224, 224, 3], name='Placeholder')\n",
    "    graph_def = load_graph(sess=sess,\n",
    "                           model_file_name='weights-floatingpoint-224x224-fixval-best/constantgraph.pb',\n",
    "                           node_mapping={'Placeholder': input_node})\n",
    "# Get the node for output\n",
    "output_node = tf.get_default_graph().get_tensor_by_name(\"import/classifier/model_1/classifier_output/Softmax:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will save the graph into a logging directory so that we can inspect it with Tensorboard.\n",
    "\n",
    "* `log_dir_name`: Path to the directory that is used to store the log. You can use `tensorboard --logdir <log_dir_name>` to inspect the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_log(log_dir_name):\n",
    "    LOGDIR='log-top-tagging-resnet50-2'\n",
    "    train_writer = tf.summary.FileWriter(log_dir_name)\n",
    "    train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will save the top-tagging model to a folder.\n",
    "\n",
    "Please change the parameter to where you want to store the Tensorboad information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_log('log-top-tagging-resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run an inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run an inference on a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    y = sess.run(output_node, feed_dict={input_node: np.zeros((2, 224, 224, 3))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00170123 0.9982988 ]\n",
      " [0.00170123 0.9982988 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are helper functions from [util.py](https://github.com/nhanvtran/MachineLearningNotebooks/blob/nvt/bwcustomweights-validate/project-brainwave/utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_rgb(images): \n",
    "    import numpy as np\n",
    "    #normalize image to 0-255 per image.\n",
    "    image_sum = 1/np.sum(np.sum(images,axis=1),axis=-1)\n",
    "    given_axis = 0\n",
    "    # Create an array which would be used to reshape 1D array, b to have \n",
    "    # singleton dimensions except for the given axis where we would put -1 \n",
    "    # signifying to use the entire length of elements along that axis  \n",
    "    dim_array = np.ones((1,images.ndim),int).ravel()\n",
    "    dim_array[given_axis] = -1\n",
    "    # Reshape b with dim_array and perform elementwise multiplication with \n",
    "    # broadcasting along the singleton dimensions for the final output\n",
    "    image_sum_reshaped = image_sum.reshape(dim_array)\n",
    "    images = images*image_sum_reshaped*255\n",
    "\n",
    "    # make it rgb by duplicating 3 channels.\n",
    "    images = np.stack([images, images, images],axis=-1)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_events(train_files):\n",
    "    import tables\n",
    "    n_events = 0\n",
    "    for train_file in train_files:\n",
    "        f = tables.open_file(train_file, 'r')\n",
    "        n_events += f.root.label.shape[0]\n",
    "        f.close()\n",
    "    return n_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(files, chunksize, max_q_size=4, shuffle=True): \n",
    "    \"\"\"Yield successive n-sized chunks from a and b.\"\"\" \n",
    "    import tables\n",
    "    import numpy as np\n",
    "    for train_file in files: \n",
    "        f = tables.open_file(train_file, 'r') \n",
    "        nrows = f.root.label.nrows\n",
    "        for istart in range(0,nrows,max_q_size*chunksize):  \n",
    "            a = np.array(f.root.img_pt[istart:istart+max_q_size*chunksize]) # Images \n",
    "            b = np.array(f.root.label[istart:istart+max_q_size*chunksize]) # Labels \n",
    "            if shuffle: \n",
    "                c = np.c_[a.reshape(len(a), -1), b.reshape(len(b), -1)] # shuffle within queue size\n",
    "                np.random.shuffle(c)\n",
    "                test_images = c[:, :a.size//len(a)].reshape(a.shape)\n",
    "                test_labels = c[:, a.size//len(a):].reshape(b.shape)\n",
    "            else:\n",
    "                test_images = a\n",
    "                test_labels = b\n",
    "            for jstart in range(0,len(test_labels),chunksize): \n",
    "                yield normalize_and_rgb(test_images[jstart:jstart+chunksize].copy()),test_labels[jstart:jstart+chunksize].copy(), len(test_labels[jstart:jstart+chunksize].copy())  \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(preds, in_images, test_files, chunk_size=64, shuffle=True):\n",
    "    \"\"\"Test the model\"\"\"\n",
    "    import tensorflow as tf\n",
    "    from keras import backend as K\n",
    "    from keras.objectives import binary_crossentropy \n",
    "    import numpy as np\n",
    "    from keras.metrics import categorical_accuracy\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    in_labels = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(binary_crossentropy(in_labels, preds))\n",
    "    accuracy = tf.reduce_mean(categorical_accuracy(in_labels, preds))\n",
    "    auc = tf.metrics.auc(tf.cast(in_labels, tf.bool), preds)\n",
    "   \n",
    "    n_test_events = count_events(test_files)\n",
    "    chunk_num = int(n_test_events/chunk_size)+1\n",
    "    preds_all = []\n",
    "    label_all = []\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    avg_accuracy = 0\n",
    "    avg_auc = 0\n",
    "    avg_test_loss = 0\n",
    "    is_training = tf.get_default_graph().get_tensor_by_name('import/is_training:0')\n",
    "    n_current_events = 0\n",
    "    for img_chunk, label_chunk, real_chunk_size in chunks(test_files, chunk_size, shuffle=shuffle):\n",
    "        test_loss, accuracy_result, auc_result, preds_result = sess.run([cross_entropy, accuracy, auc, preds],\n",
    "                        feed_dict={in_images: img_chunk,\n",
    "                                   in_labels: label_chunk,\n",
    "                                   K.learning_phase(): 0,\n",
    "                                   is_training: False})\n",
    "        avg_test_loss += test_loss * real_chunk_size / n_test_events\n",
    "        avg_accuracy += accuracy_result * real_chunk_size / n_test_events\n",
    "        avg_auc += auc_result[0]  * real_chunk_size / n_test_events \n",
    "        preds_all.extend(preds_result)\n",
    "        label_all.extend(label_chunk)\n",
    "        n_current_events += real_chunk_size\n",
    "    \n",
    "        print(\"test_loss = \", \"{:.3f}\".format(avg_test_loss*n_test_events/n_current_events), end=\"\")\n",
    "        print(\"Test Accuracy:\", \"{:.3f}\".format(avg_accuracy*n_test_events/n_current_events), \", Area under ROC curve:\", \"{:.3f}\".format(avg_auc*n_test_events/n_current_events))\n",
    "    \n",
    "    return avg_test_loss, avg_accuracy, avg_auc, np.asarray(preds_all).reshape(n_test_events,2), np.asarray(label_all).reshape(n_test_events,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will test the model on a test file.\n",
    "\n",
    "Please change the parameter so that it uses the correct file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss =  0.229Test Accuracy: 0.922 , Area under ROC curve: 0.000\n",
      "test_loss =  0.259Test Accuracy: 0.922 , Area under ROC curve: 0.484\n",
      "test_loss =  0.259Test Accuracy: 0.922 , Area under ROC curve: 0.645\n",
      "test_loss =  0.290Test Accuracy: 0.906 , Area under ROC curve: 0.726\n",
      "test_loss =  0.276Test Accuracy: 0.906 , Area under ROC curve: 0.774\n",
      "test_loss =  0.251Test Accuracy: 0.911 , Area under ROC curve: 0.807\n",
      "test_loss =  0.245Test Accuracy: 0.915 , Area under ROC curve: 0.831\n",
      "test_loss =  0.268Test Accuracy: 0.908 , Area under ROC curve: 0.849\n",
      "test_loss =  0.252Test Accuracy: 0.911 , Area under ROC curve: 0.863\n",
      "test_loss =  0.258Test Accuracy: 0.909 , Area under ROC curve: 0.874\n",
      "test_loss =  0.264Test Accuracy: 0.908 , Area under ROC curve: 0.883\n",
      "test_loss =  0.275Test Accuracy: 0.902 , Area under ROC curve: 0.891\n",
      "test_loss =  0.276Test Accuracy: 0.900 , Area under ROC curve: 0.897\n",
      "test_loss =  0.273Test Accuracy: 0.901 , Area under ROC curve: 0.902\n",
      "test_loss =  0.283Test Accuracy: 0.899 , Area under ROC curve: 0.907\n",
      "test_loss =  0.276Test Accuracy: 0.903 , Area under ROC curve: 0.911\n",
      "test_loss =  0.274Test Accuracy: 0.903 , Area under ROC curve: 0.914\n",
      "test_loss =  0.279Test Accuracy: 0.900 , Area under ROC curve: 0.917\n",
      "test_loss =  0.280Test Accuracy: 0.900 , Area under ROC curve: 0.920\n",
      "test_loss =  0.278Test Accuracy: 0.902 , Area under ROC curve: 0.923\n",
      "test_loss =  0.277Test Accuracy: 0.903 , Area under ROC curve: 0.925\n",
      "test_loss =  0.281Test Accuracy: 0.901 , Area under ROC curve: 0.927\n",
      "test_loss =  0.289Test Accuracy: 0.898 , Area under ROC curve: 0.929\n",
      "test_loss =  0.290Test Accuracy: 0.898 , Area under ROC curve: 0.930\n",
      "test_loss =  0.291Test Accuracy: 0.898 , Area under ROC curve: 0.932\n",
      "test_loss =  0.287Test Accuracy: 0.899 , Area under ROC curve: 0.933\n",
      "test_loss =  0.289Test Accuracy: 0.900 , Area under ROC curve: 0.934\n",
      "test_loss =  0.287Test Accuracy: 0.902 , Area under ROC curve: 0.936\n",
      "test_loss =  0.300Test Accuracy: 0.899 , Area under ROC curve: 0.937\n",
      "test_loss =  0.299Test Accuracy: 0.899 , Area under ROC curve: 0.938\n",
      "test_loss =  0.299Test Accuracy: 0.898 , Area under ROC curve: 0.938\n",
      "test_loss =  0.297Test Accuracy: 0.899 , Area under ROC curve: 0.939\n",
      "test_loss =  0.306Test Accuracy: 0.894 , Area under ROC curve: 0.940\n",
      "test_loss =  0.308Test Accuracy: 0.893 , Area under ROC curve: 0.941\n",
      "test_loss =  0.308Test Accuracy: 0.893 , Area under ROC curve: 0.941\n",
      "test_loss =  0.309Test Accuracy: 0.893 , Area under ROC curve: 0.942\n",
      "test_loss =  0.309Test Accuracy: 0.892 , Area under ROC curve: 0.943\n",
      "test_loss =  0.311Test Accuracy: 0.891 , Area under ROC curve: 0.943\n",
      "test_loss =  0.310Test Accuracy: 0.891 , Area under ROC curve: 0.944\n",
      "test_loss =  0.313Test Accuracy: 0.890 , Area under ROC curve: 0.944\n",
      "test_loss =  0.317Test Accuracy: 0.890 , Area under ROC curve: 0.945\n",
      "test_loss =  0.320Test Accuracy: 0.890 , Area under ROC curve: 0.945\n",
      "test_loss =  0.319Test Accuracy: 0.891 , Area under ROC curve: 0.945\n",
      "test_loss =  0.322Test Accuracy: 0.890 , Area under ROC curve: 0.946\n",
      "test_loss =  0.324Test Accuracy: 0.891 , Area under ROC curve: 0.946\n",
      "test_loss =  0.323Test Accuracy: 0.892 , Area under ROC curve: 0.947\n",
      "test_loss =  0.323Test Accuracy: 0.892 , Area under ROC curve: 0.947\n",
      "test_loss =  0.321Test Accuracy: 0.893 , Area under ROC curve: 0.947\n",
      "test_loss =  0.317Test Accuracy: 0.894 , Area under ROC curve: 0.948\n",
      "test_loss =  0.324Test Accuracy: 0.892 , Area under ROC curve: 0.948\n",
      "test_loss =  0.325Test Accuracy: 0.892 , Area under ROC curve: 0.948\n",
      "test_loss =  0.331Test Accuracy: 0.892 , Area under ROC curve: 0.948\n",
      "test_loss =  0.330Test Accuracy: 0.892 , Area under ROC curve: 0.949\n",
      "test_loss =  0.335Test Accuracy: 0.890 , Area under ROC curve: 0.949\n",
      "test_loss =  0.334Test Accuracy: 0.890 , Area under ROC curve: 0.949\n",
      "test_loss =  0.334Test Accuracy: 0.889 , Area under ROC curve: 0.949\n",
      "test_loss =  0.331Test Accuracy: 0.890 , Area under ROC curve: 0.949\n",
      "test_loss =  0.330Test Accuracy: 0.890 , Area under ROC curve: 0.950\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c57bba93ea2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'img224_all/converted/rotation_224_v1/test_file_0.h5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-08bd62f53245>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(preds, in_images, test_files, chunk_size, shuffle)\u001b[0m\n\u001b[1;32m     32\u001b[0m                                    \u001b[0min_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                    \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                    is_training: False})\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mavg_test_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreal_chunk_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_test_events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mavg_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_result\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreal_chunk_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_test_events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_model(output_node, input_node, ['img224_all/converted/rotation_224_v1/test_file_0.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from .h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `file_name` to the path of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "classifier_output (Dense)    (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 2,100,226\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "file_name = '../weights-quantized-224x224-fixval-best-final/class_model_best.h5'\n",
    "new_model = keras.models.load_model(file_name)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
